{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red53\green53\blue53;}
{\*\expandedcolortbl;;\cssrgb\c27059\c27059\c27059;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab560
\pard\pardeftab560\slleading20\pardirnatural\partightenfactor0

\f0\fs24 \cf2 System Identification Presentation Notes\
\
Next, we show the pole/zero and bode plots of the ARX model and the state space model estimated using subspace method. \
\
The first figure shows the pole-zero map of an ARX model with model order na=nb=6, along with 95% confidence region. We can see that for the left two complex conjugate poles, there are some uncertainties. And most importantly, we can only observe 5 zeros in the plot. This is because the two zeros in the middle of the plot almost completely overlapped, which means that we can decrease one model order in the numerator of the plant model. \
\
This figure shows the pole/zero plot of the ARX model with model order na = 6, and nb =5. We can see that by decreasing one model order in the numerator, the uncertainties of the left two complex conjugate poles are also decreased. \
\
The third pole/zero plot corresponds to the state space model with order 6. Here can we can see that there is a real pole on the right half plane. This means that the system has an unstable gain. This can be also verified from this bode plot that for the state space model, the magnitude increases exponentially in the last part.  Here, we can see that the gain margin for the estimated models when phase is at -180 degree, close to the Nyquist frequency varies a lot compared to the empirical transfer function estimate, which is almost constant. This can be further verified by examining the spectral density of the data, which has very low power in high frequency part, which means for the high frequency part, not enough information is provided to give a good model estimation. \
\
This figure shows the simulation error of different models. Here, it is obvious to see that for the state space model estimated using prediction error method has the worst performance.  This figure shows the comparison of different models. For the plots on the diagonal, the simulated output is compared to true data. We can see that the OE model and the transfer function model are very similar. It is due to the fact that the only difference between these two models is that for the transfer function model, there is a feedthrough option that allows us to choose b0 in the numerator, while b0 is always zero in the OE model. This figure shows that the ARX model has less simulation error. \
\
Next, we did the residual analysis regarding its autocorrelation and its cross-correlation with the input. For a perfect-fitting model, the auto or cross correlation with the input should be zero expect when the lag is zero. From this figure, we can see that the ARX model and the state space model estimated using subspace method are better than the rests. However, from this cross-correlation plot, we can see that the state space model is not very good due to the correlation is not zero when the lag is large and that the normalised magnetite also often exceeds the 95% confidence region. Overall, the ARX model is the best. \
\
We also did some non-linear identification on our data. If we can obtain better performance using nonlinear model, then we can say that there are some non-linearities existing in our model. We tried the non-linear ARX model and the Hammerstein-Wiener model. Hammerstein-Wiener models describe dynamic systems using one or two static nonlinear blocks in series with a linear OE block, whereas in the non-linear ARX model, the regressors are followed by a non-linearity block. For the non-linear models, we can either choose to use the default option or we can initialize the non-linear system identification with an identified linear model, which means that the we start the model estimation with the linear model and begin the search by adding some non-linearities. However, from this figure we can see that, adding non-linearities to the linear model does not improve the model fitting rate. From this, we can infer that there is little or no non-linearity in the true model. \
\
\
}