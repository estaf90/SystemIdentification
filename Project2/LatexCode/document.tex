\documentclass[]{article}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[outdir=./]{epstopdf}
\usepackage{booktabs}
\usepackage{float}
\usepackage{subcaption}

\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

\DeclareMathOperator{\cov}{cov}

%opening
\title{SSY 230, System Identification\\
	Project 1: Estimating functions from noisy data}
\author{Yuxuan Xia\\ \href{mailto:yuxuan.xia@chalmers.se}{yuxuan.xia@chalmers.se}\\Emil Staf\\\href{mailto:emil.staf@chalmers.se}{emil.staf@chalmers.se}}

\begin{document}

\maketitle

\section{ARX estimator}
\subsection{(a) arxfit}
The \emph{arxfit} fucntion can beneficially be implemented using the Linear Regression code written in Project 1. The ARX model is given by
\begin{align}
	\label{eq:ARX}
	A(q^{-1})y(t) &= B(q^{-1})u(t) + e(t) \\
	\theta &= (a_1, \ldots a_{na}, b_1, \ldots, b_{nb})^\mathsf{T}
\end{align}
according to (6.13a) in S \& S. This can be rewritten on a Linear Regression format
\begin{equation}
	\label{eq:ARX_LR}
	y(t) = \phi(t) \theta + e(t)
\end{equation}
where
\begin{equation}
	\label{eq:ARX_LR_phi}
	\phi(t) = (-y(t-1), \ldots, -y(t-na), u(t-1-nk), \ldots, u(t-1-nk-nb))^\mathsf{T}
\end{equation}
The function arxfit is implemented accordingly. It was verified against the function 
\begin{equation}
	\label{eq:system}
	y(t) = 0.2y(t-1) - 0.3y(t-2) + 0.4u(t-2) - 0.2u(t-3)
\end{equation}
without any noise, and the correct model was obtained.

\subsection{(b) id2tf}
The function \emph{id2tf} is implemented using MATLABs build-in function \emph{tf(Numerator, Denominator, `Variable', `$q^{-1}$')} where \emph{Numerator} = $(\hat{b}_1, \ldots, \hat{b}_{nb})$ and \emph{Denominator} = $(1, \hat{a}_1, \ldots, \hat{a}_{na})$. In Figure \ref{fig:1b-ltiview} the build-in MATLAB function \emph{ltiview} was used to analyze the model found in (a) including noise.

\begin{figure}[ht]
\centering
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/1b-pzmap.pdf}
	\caption{pzmap using ltiview}
	\label{fig:1b-pzmap}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/1b-step.pdf}
	\caption{Step response using ltiview}
	\label{fig:1b-step}
\end{subfigure}
\caption{MATLABs build in function \emph{ltiview} analyzing the found ARX model for the system in \eqref{eq:system} including noise.}
\label{fig:1b-ltiview}
\end{figure}

\subsection{(c) idpredict and idsimulate}
A $k$-step predictor for an ARX model can be fund by studying the following equations.
\begin{align}
	\label{eq:K-step predictor}
	\hat{y}(t|t-1) &= -a_1y(t-1) -a_2y(t-2) \ldots \\
	\hat{y}(t|t-2) &= -a_1\hat{y}(t-1|t-2) -a_2y(t-2) \ldots \\
	\hat{y}(t|t-3) &= -a_1\hat{y}(t-1|t-3) -a_2\hat{y}(t-2|t-3) \ldots 
\end{align}
It is possible to use the 1-step ahead predictor to calculate the 2-step predictor, the 1-step and 2-step predictor to calculate the 3-step predictor and so on. It is the regressor matrix $\Phi_i = [Y_i, U]$ that needs to be updated in a clever way in order to achieve fast matrix calculations which is shown below. The $U$ matrix is constant and given by

\begin{equation}
	U = \begin{bmatrix}
		u(0-n_k) & u(-1-n_k) & \ldots & u(1-n_b-n_k) \\
		u(1-n_k) & u(0-n_k) & \ldots & u(2-n_b-n_k) \\
		u(2-n_k) & u(1-n_k) & \ldots & u(3-n_b-n_k) \\
		\vdots & \vdots & \vdots & \vdots \\
		u(n-1-n_k) & u(n-2-n_k) & \ldots & u(n-n_b-n_k) \\
	\end{bmatrix}
\end{equation}
while
\begin{equation}
	Y_1 = \begin{bmatrix}
		y(0) & y(-1) & \ldots & y(1-n_a) \\
		y(1) & y(0) &\ldots & y(2-n_a) \\
		y(2) & y(1) &\ldots & y(3-n_a) \\
		\vdots & \vdots & \vdots & \vdots \\
		y(n-1) & y(n-2) & \ldots & y(n-n_a) \\
	\end{bmatrix}
\end{equation}
\begin{equation}
	Y_2 = \begin{bmatrix}
		\hat{y}(0|-1) & y(-1) & \ldots & y(1-n_a) \\
		\hat{y}(1|0) & y(0) &\ldots & y(2-n_a) \\
		\hat{y}(2|1) & y(1) &\ldots & y(3-n_a) \\
		\vdots & \vdots & \vdots & \vdots \\
		\hat{y}(n-1|n-2) & y(n-2) & \ldots & y(n-n_a) \\
	\end{bmatrix}
\end{equation}
\begin{equation}
Y_3 = \begin{bmatrix}
		\hat{y}(0|-2) & \hat{y}(-1|-2) & \ldots & y(1-n_a) \\
		\hat{y}(1|-1) & \hat{y}(0|-1) &\ldots & y(2-n_a) \\
		\hat{y}(2|0) & \hat{y}(1|0) &\ldots & y(3-n_a) \\
		\vdots & \vdots & \vdots & \vdots \\
		\hat{y}(n-1|n-3) & \hat{y}(n-2|n-1) & \ldots & y(n-n_a) \\
	\end{bmatrix}
\end{equation}
where $\hat{y}(t|t-k) = \Phi_k \hat{\theta}$ and the values for both $y$ and $u$ prior to $t=1$ are initialized to zero.

Simulation can be performed by setting $k > n$, i.e. the predictor is forced not to use any of the measured outputs. 

\subsection{(d) idcompare}
Some results for the same system as before \eqref{eq:system} are compared using \emph{idcompare}, along with their prediction/simulation uncertainties, see Figure \ref{fig:1d}.
\begin{figure}[ht]
\centering
\begin{subfigure}{.30\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.3]{figures/1d-horizon_1.pdf}
	\caption{Horizon 1}
	\label{fig:1d-horizon1}
\end{subfigure}
\begin{subfigure}{.30\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.3]{figures/1d-horizon_5.pdf}
	\caption{Horizon 5}
	\label{fig:1d-horizon5}
\end{subfigure}
\begin{subfigure}{.30\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.3]{figures/1d-horizon_10.pdf}
	\caption{Horizon 10}
	\label{fig:1d-horizon10}
\end{subfigure}
\caption{Some results using the implemented \emph{idcompare} function. It is clear that the model uncertainty is increasing for increasing horizons, which means that less data is allowed in the prediction step. The mse on validation data is also increasing as the horizon is increasing.}
\label{fig:1d}
\end{figure}

When we estimate the model parameters from data, we also obtain their estimation covariance, with the help of which, we can visualize how accurate our estimations are in a condence region. The magnitude of the uncertainties provide a measure of the reliability of the model. With the help of MATLAB System Identifcation toolbox, we can compute and visualize the effect of parameter uncertainties on the model response in time and frequency domains using pole-zero maps, Bode plot, and step response plots, etc.


\section{Write an OE estimator}

\subsection{(a) oefit}
Having the Output-Error system
\begin{equation}
	S: y(t) = \frac{B_0(q)}{A_0(q)}u(t) + e(t).
\end{equation}
Estimating a high order ARX model $A_h(q)y(t) = B_h(q)u(t) + e(t)$ it is possible to acheive a close approximation to the system behavior, i.e. $\frac{B_h(q)}{A_h(q)} \approx \frac{B_0(q)}{A_0(q)}$. Thus by simulating the higher order ARX system it is possible to get noise free data that closely resembles the system we are trying to model
\begin{equation}
	y_s(t) = \frac{B_h(q)}{A_h(q)}
\end{equation}

Adding white noise to the output signal given that the number of data is high, we can re-obtain the true parameters using an OE model; however, this is not the case for ARX model. This difference is a direct consequence of the different ways modeling the system disturbances in the OE and the ARX model. In the OE model, system disturbances are directly added to the output signal, whereas in the ARX model, system disturbances are part of the system dynamics.

Now using the noise free data, an ARX model fit becomes the same as an OE model fit. Thus we obtain our OE prediction $\hat{y}(t) = \frac{\hat{B(q)}}{\hat{A}(q)}u(t) + e(t)$ from the ARX model fit $\hat{A}(q)y_s(t) = \hat{B(q)}u(t)$. The prediction error then becomes $| \frac{B_0(q)}{A_0(q)}u(t) - \frac{\hat{B(q)}}{\hat{A}(q)}u(t)|$, which is minimized for $\frac{B_h(q)}{A_h(q)} = \frac{B_0(q)}{A_0(q)}$.

We have also successfully implemented the OE model using this optimal method specifed in the problem description, i.e., fltering the simulated and input data using a FIR flter with parameter Ah before estimating using the ARX model with original order, see attached MATLAB file.

\subsection{(b) id2tf}
No changes from ARX.

\subsection{(c) idpredict}
According to the lecture notes a $k$-step predictor can be written on the form
\begin{equation}
	\label{eq:K-step Prediction}
	\hat{y}(t|t-k) = \bar{H}_k(q)H^{-1}(q)G(q)u(t) + (1-\bar{H}_k(q)H^{-1}(q))y(t)
\end{equation}
which for an OE-model simplifies to
\begin{equation}
	\label{eq:K-step Prediction OE}
	\hat{y}(t|t-k) = G(q)u(t)
\end{equation}
since $H^{-1}(q)=1$ and $\bar{H}_k^{-1}(q)=1$ for all $k > 1$. Therefore prediction is the same as simulation for the OE-model and the \emph{idpredict} function calls the \emph{idsimulate} function in the case of an OE-model.

\subsection{(d) idsimulate}
Using the MATLAB build in function \emph{lsim} after creating the OE transfer function by calling \emph{id2tf}.

\subsection{(e) idcompare}
No specific changes from ARX except that the prediction and simulation are the same so one of them were removed in the plots.
Showing only the prediction since simulation is the same as stated above. This can be seen in the Figure \ref{fig:2e-validation}, where OE-data was created and an ARX-model is compared to an OE-model.

\begin{figure}[ht]
\centering
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/2e-ARX-horizon_1.pdf}
	\caption{ARX-model}
	\label{fig:2e-ARX-horizon_1}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/2e-OE-horizon_1.pdf}
	\caption{OE-model}
	\label{fig:2e-OE-horizon_1}
\end{subfigure}
\caption{OE-model vs ARX-model on OE system of order nb = 2, nf = 2, nk = 1.}
\label{fig:2e-validation}
\end{figure}
As can be seen in Figure \ref{fig:2e-validation} the model uncertainty is substantially smaller for the OE-model in comparison to the ARX model.

\section{Identify two systems}

\subsection{Results on data set exercise1}

\begin{figure}[ht]
\centering
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-ARX-Ex1-idcompare.pdf}
	\caption{ARX}
	\label{fig:Ex1-idcompare-ARX}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-OE-Ex1-idcompare.pdf}
	\caption{OE}
	\label{fig:Ex1-idcompare-OE}
\end{subfigure}
\caption{Dataset exercise1}
\label{fig:Ex1-idcompare}
\end{figure}

\begin{figure}[ht]
\centering
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-ARX-Ex1.pdf}
	\caption{ARX}
	\label{fig:Ex1-ARX}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-OE-Ex1.pdf}
	\caption{OE}
	\label{fig:Ex1-OE}
\end{subfigure}
\caption{Dataset exercise1, using build-in MATLAB plotting functionality.}
\label{fig:Ex1}
\end{figure}

The results on exercise1 data shows that both the ARX and OE system are stable and that they produce prediction results of similar accuracy. It is therfore possible to use either of the models to model the stable system generating exercise1 data. We choose the model according to the Parcimony Principle and that is the ARX model which has a total of 9 parameters while the OE model has a total of 12 parameters.

\subsection{Results on data set exercise2}

\begin{figure}[ht]
\centering
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-ARX-Ex2-idcompare.pdf}
	\caption{ARX}
	\label{fig:Ex2-idcompare-ARX}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-OE-Ex2-idcompare.pdf}
	\caption{OE}
	\label{fig:Ex2-idcompare-OE}
\end{subfigure}
\caption{Dataset exercise2}
\label{fig:Ex2-idcompare}
\end{figure}

\begin{figure}[ht]
\centering
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-ARX-Ex2.pdf}
	\caption{ARX}
	\label{fig:Ex2-ARX}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-OE-Ex2.pdf}
	\caption{OE}
	\label{fig:Ex2-OE}
\end{subfigure}
\caption{Dataset exercise2, using build-in MATLAB plotting functionality.}
\label{fig:Ex2}
\end{figure}

In Figure \ref{fig:Ex2-ARX} there are three zeros and poles that are close and should cancel each other out. This means that we probably have chosen a too high model order and are likely to overfit the data. After reducing the model order the result in figure \ref{fig:Ex2-ARX-cancel} is obtained.

\begin{figure}[ht]
\centering
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-ARX-Ex2-cancel_out.pdf}
	\caption{\emph{ltiview}}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
	\centering
	\includegraphics[trim= 10cm 8cm 10cm 8cm, scale=0.4]{figures/3-ARX-Ex2-idcompare-cancel_out.pdf}
	\caption{\emph{idcompare}}
\end{subfigure}
\caption{ARX result after canceling out some zeros and poled from dataset exercise2.}
\label{fig:Ex2-ARX-cancel}
\end{figure}

It is obvious from Figure \ref{fig:Ex2-ARX-cancel} that the system modelled is unstable due to the large MSE for the simulated ARX model. Due to the fact that the simulated output from an ARX model is used to find the parameters for the OE model, it does not make sense using it to model an unstable system by making use of the simulated output which does not match the true system at all. Thus, the ARX model is the prefered model for exercise2 data.

\end{document}
